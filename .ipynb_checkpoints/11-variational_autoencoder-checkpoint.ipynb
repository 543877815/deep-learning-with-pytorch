{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76633,
     "status": "ok",
     "timestamp": 1576496945373,
     "user": {
      "displayName": "李逢君",
      "photoUrl": "",
      "userId": "18366437668309960801"
     },
     "user_tz": -480
    },
    "id": "_BvVvHkIh-fb",
    "outputId": "3a98e47e-2ed9-4ca9-d399-a70dbe066539"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:06, 1615111.96it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28881 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 129511.19it/s]           \n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 2152304.36it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 49615.16it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 34386.4766, KL Div: 3294.5908\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29643.0098, KL Div: 1097.1932\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 27014.9023, KL Div: 1317.5890\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 26063.0039, KL Div: 733.5487\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 26622.0781, KL Div: 723.9581\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 25685.2891, KL Div: 908.2443\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 25217.9844, KL Div: 960.0610\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 23632.4590, KL Div: 1070.0254\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 22505.8535, KL Div: 1205.5720\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 21855.6484, KL Div: 1352.8986\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 21458.4199, KL Div: 1484.5049\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 20283.7070, KL Div: 1619.4189\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 20011.1758, KL Div: 1701.4480\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 20701.8848, KL Div: 1667.3960\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 19906.1699, KL Div: 1966.5652\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 18760.7051, KL Div: 1987.9421\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18611.7285, KL Div: 2098.0159\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 18823.6699, KL Div: 1918.1523\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 18042.9180, KL Div: 1911.6443\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 17069.5723, KL Div: 2055.6331\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 17300.9199, KL Div: 2122.7056\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 16496.0820, KL Div: 2148.7080\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 16746.2539, KL Div: 2191.7749\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 16787.6016, KL Div: 2235.1924\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 16293.2090, KL Div: 2061.8008\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 14786.2002, KL Div: 2225.6680\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 16227.8691, KL Div: 2118.0828\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 15803.1738, KL Div: 2228.0999\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 15608.7812, KL Div: 2387.4092\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 16092.2793, KL Div: 2263.7061\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 16016.3730, KL Div: 2274.8923\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 16321.5762, KL Div: 2262.7288\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 15494.0840, KL Div: 2345.1843\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 15187.7695, KL Div: 2450.2385\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 14402.4824, KL Div: 2296.2402\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 14697.0557, KL Div: 2402.5015\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 14724.2627, KL Div: 2497.5479\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 14599.5918, KL Div: 2493.5269\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 14666.9072, KL Div: 2540.2930\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14921.9990, KL Div: 2484.6643\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 14422.9648, KL Div: 2603.6504\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 14518.9424, KL Div: 2541.0769\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 14011.8848, KL Div: 2532.1440\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 14466.8770, KL Div: 2467.2583\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 13841.2754, KL Div: 2598.6919\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 14368.7432, KL Div: 2749.4307\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 14244.8965, KL Div: 2572.9934\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 13124.7500, KL Div: 2593.7019\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 13759.0488, KL Div: 2838.6411\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 13250.2363, KL Div: 2553.3530\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 13401.8066, KL Div: 2740.7861\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 13051.9053, KL Div: 2743.9424\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 13235.9795, KL Div: 2601.3459\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 13567.5566, KL Div: 2727.5200\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 12770.3369, KL Div: 2695.9377\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 13153.6953, KL Div: 2759.6880\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 13191.0293, KL Div: 2740.9431\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 13654.9834, KL Div: 2713.4502\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 12618.6543, KL Div: 2688.4604\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 12603.7676, KL Div: 2696.9924\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 12730.9180, KL Div: 2879.4746\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 13459.8730, KL Div: 2808.6187\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 13164.3477, KL Div: 2809.1060\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 12726.4639, KL Div: 2800.8071\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 13169.8379, KL Div: 2781.6440\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 12487.5215, KL Div: 2816.0657\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 12126.3721, KL Div: 2829.2192\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 12405.8369, KL Div: 2861.9531\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12356.2617, KL Div: 2841.2349\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12931.4961, KL Div: 2943.4839\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 12582.2734, KL Div: 2777.8452\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12540.9648, KL Div: 2902.9011\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 13127.9717, KL Div: 2971.5771\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 12345.2480, KL Div: 2899.2246\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 11895.4023, KL Div: 2823.2197\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 12122.4668, KL Div: 2884.0991\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 12471.7666, KL Div: 2904.9802\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 12567.6660, KL Div: 2873.3694\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 11779.5410, KL Div: 2957.3647\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 12485.1660, KL Div: 2888.8340\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 12114.1025, KL Div: 2923.3650\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 12327.3711, KL Div: 2903.7905\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 12301.2178, KL Div: 3016.0938\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 12136.4053, KL Div: 2938.1619\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 12163.6650, KL Div: 2940.4402\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 11784.0186, KL Div: 2928.9014\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 12099.5518, KL Div: 2906.2202\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 12223.5596, KL Div: 2996.0972\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 11542.3975, KL Div: 2865.8418\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 11536.8379, KL Div: 2946.7988\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 11935.2461, KL Div: 3026.9487\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 11776.9023, KL Div: 2928.7593\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 11592.7109, KL Div: 2936.5854\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 11810.3838, KL Div: 3126.3213\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 12016.4199, KL Div: 2988.8872\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 11863.4473, KL Div: 3127.9097\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 11625.7520, KL Div: 3084.8794\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 11269.5000, KL Div: 2904.3438\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 11814.4609, KL Div: 3186.5894\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 11368.1533, KL Div: 3017.6467\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 11538.1543, KL Div: 3084.7969\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 11570.2871, KL Div: 3062.7705\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 11281.6709, KL Div: 3019.2793\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11375.2324, KL Div: 3101.7222\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 11703.0957, KL Div: 3096.8054\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11647.5771, KL Div: 3075.1284\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 12202.9287, KL Div: 3032.9084\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11719.8916, KL Div: 3077.2666\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 11833.1982, KL Div: 3085.8413\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 11349.6914, KL Div: 3032.5044\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 11447.1387, KL Div: 3116.9946\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11457.0078, KL Div: 3067.2102\n",
      "Epoch[3/15], Step [210/469], Reconst Loss: 11489.6904, KL Div: 3009.7749\n",
      "Epoch[3/15], Step [220/469], Reconst Loss: 11276.7324, KL Div: 3077.3232\n",
      "Epoch[3/15], Step [230/469], Reconst Loss: 11868.7285, KL Div: 3123.5298\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11811.1191, KL Div: 3219.5347\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11760.6230, KL Div: 3116.9915\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 11352.1787, KL Div: 3123.0273\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 11476.6484, KL Div: 3006.7427\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11498.1152, KL Div: 3062.8276\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 11713.0420, KL Div: 3183.3672\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11717.9590, KL Div: 3147.2104\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 11633.7188, KL Div: 3032.9619\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11509.4170, KL Div: 3221.7410\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11670.9180, KL Div: 3015.9336\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11450.2568, KL Div: 3042.1790\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 11159.3828, KL Div: 3043.2134\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 11859.7637, KL Div: 3151.0176\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 10938.0000, KL Div: 3097.3848\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 10901.3066, KL Div: 3061.7083\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11264.5273, KL Div: 3012.1519\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 11341.3730, KL Div: 3168.8203\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 10858.1953, KL Div: 3043.1460\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 11662.1543, KL Div: 3125.5203\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 11356.8418, KL Div: 3156.1768\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 11348.1475, KL Div: 3205.3325\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 11548.5801, KL Div: 3044.7446\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 11287.0918, KL Div: 3113.3735\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 11102.8486, KL Div: 3111.1797\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 11579.9600, KL Div: 3079.5254\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 10261.0332, KL Div: 3044.4976\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 10748.5020, KL Div: 3089.2598\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11196.9805, KL Div: 3096.9177\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 11024.5176, KL Div: 3148.7837\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 11401.6465, KL Div: 3159.0552\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 10996.8691, KL Div: 3108.3506\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 11306.5703, KL Div: 3212.6274\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 11243.6602, KL Div: 3095.9866\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 10898.8037, KL Div: 3099.7747\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 11092.9326, KL Div: 3105.8491\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 11273.3730, KL Div: 3067.3279\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 11270.1631, KL Div: 3186.4226\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 11001.7656, KL Div: 3150.4121\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 10921.2295, KL Div: 3118.7917\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 11643.4141, KL Div: 3188.0432\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 10767.7842, KL Div: 3088.9062\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 10598.2168, KL Div: 3001.2021\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 11462.1553, KL Div: 3160.6995\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 10896.3613, KL Div: 3079.8000\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 10514.2188, KL Div: 3037.7144\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 10710.6143, KL Div: 3067.5645\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 11156.7676, KL Div: 3138.8354\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 10818.8965, KL Div: 3156.3198\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 10532.7529, KL Div: 3142.8315\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 11095.5459, KL Div: 3089.8745\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 11449.0703, KL Div: 3141.2014\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 10662.2129, KL Div: 3010.0117\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 10636.8486, KL Div: 3233.4639\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 10801.6416, KL Div: 3178.5364\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 10841.5908, KL Div: 3137.0979\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 10649.2051, KL Div: 3188.8755\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 11423.8008, KL Div: 3096.6272\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 11484.8623, KL Div: 3264.0017\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 10864.7578, KL Div: 3089.2058\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 10356.0566, KL Div: 3094.1853\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 10572.7012, KL Div: 3055.2615\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 11024.3613, KL Div: 3189.0098\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 10960.5918, KL Div: 3173.2749\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 10945.7490, KL Div: 3125.3774\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 11095.7773, KL Div: 3180.1235\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 11112.3906, KL Div: 3184.5730\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 10486.6670, KL Div: 3122.5364\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 10847.3281, KL Div: 3202.7173\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 10644.7109, KL Div: 3049.6335\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 10342.3535, KL Div: 3123.8804\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 10785.3760, KL Div: 3123.1187\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 10795.5508, KL Div: 3171.0798\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 11097.7715, KL Div: 3170.5664\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 11094.2900, KL Div: 3062.4297\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 10709.2090, KL Div: 3057.7588\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 10702.5410, KL Div: 3194.3711\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 11211.3525, KL Div: 3165.4199\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 10731.9395, KL Div: 3125.2944\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 10560.5400, KL Div: 3169.5010\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 11126.1348, KL Div: 3138.3613\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 11048.8242, KL Div: 3145.2812\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 10581.9834, KL Div: 3212.6304\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 10810.2568, KL Div: 3119.3740\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 10196.2295, KL Div: 3133.8359\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 11186.1709, KL Div: 3249.4514\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 10696.6299, KL Div: 3205.0410\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 10366.0215, KL Div: 3192.6755\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 10583.4141, KL Div: 3179.4993\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10699.1738, KL Div: 3140.7646\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 10680.9482, KL Div: 3239.9102\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 11148.7148, KL Div: 3246.6680\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 10891.6758, KL Div: 3155.1199\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 11025.0332, KL Div: 3222.6855\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 11289.3125, KL Div: 3146.6309\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 11303.4902, KL Div: 3232.0483\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 10826.3506, KL Div: 3172.8589\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 10670.0098, KL Div: 3213.7065\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 10277.7988, KL Div: 3105.0786\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 10981.2803, KL Div: 3211.6934\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 11203.4736, KL Div: 3200.7544\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 10447.4980, KL Div: 3174.3105\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 10434.8184, KL Div: 3060.2961\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 11296.4463, KL Div: 3240.8916\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 11078.1035, KL Div: 3095.4268\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 10723.0762, KL Div: 3219.0781\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 10830.8906, KL Div: 3263.5801\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 10815.2246, KL Div: 3182.2773\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 10733.6787, KL Div: 3160.6648\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10583.4912, KL Div: 3222.9182\n",
      "Epoch[5/15], Step [410/469], Reconst Loss: 11240.3359, KL Div: 3192.4087\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 10592.6191, KL Div: 3170.5044\n",
      "Epoch[5/15], Step [430/469], Reconst Loss: 11092.6855, KL Div: 3094.5674\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 10825.2344, KL Div: 3121.1572\n",
      "Epoch[5/15], Step [450/469], Reconst Loss: 11286.2715, KL Div: 3147.2927\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 10769.3477, KL Div: 3361.4888\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 10237.7773, KL Div: 3113.8311\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 10758.0371, KL Div: 3216.7563\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 10506.2812, KL Div: 3075.5454\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 10748.2012, KL Div: 3399.6023\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 10332.0361, KL Div: 3057.3201\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 10765.9775, KL Div: 3193.3250\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 11398.4512, KL Div: 3280.7646\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 10459.6953, KL Div: 3145.4006\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 10403.0645, KL Div: 3156.4155\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10224.2539, KL Div: 3128.3955\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 10852.5820, KL Div: 3109.7390\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 10407.6973, KL Div: 3212.6238\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 10883.9521, KL Div: 3224.9446\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10707.1768, KL Div: 3117.0640\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 10963.5469, KL Div: 3200.5413\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 10579.9551, KL Div: 3190.6665\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 10741.2930, KL Div: 3210.7485\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 10391.9150, KL Div: 3155.9980\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 10594.5527, KL Div: 3098.0903\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10647.2031, KL Div: 3280.8828\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 10630.8770, KL Div: 3202.2642\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 10558.8496, KL Div: 3197.1472\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 11549.2871, KL Div: 3277.9685\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10452.1240, KL Div: 3112.9856\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 11150.8809, KL Div: 3347.1421\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 9847.3545, KL Div: 3130.2104\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10775.3232, KL Div: 3177.5762\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 11244.9160, KL Div: 3229.8845\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 10450.7803, KL Div: 3184.0928\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10615.1855, KL Div: 3218.5625\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 10357.1182, KL Div: 3299.9175\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 11329.1533, KL Div: 3295.9131\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 10767.9639, KL Div: 3335.1069\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 10515.4961, KL Div: 3222.4136\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 10253.5254, KL Div: 3148.0366\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10609.8652, KL Div: 3199.4854\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 11034.0088, KL Div: 3247.6018\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10343.8037, KL Div: 3211.9390\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10897.4824, KL Div: 3218.4614\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10682.1797, KL Div: 3260.2710\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 11152.0215, KL Div: 3169.2988\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10440.4775, KL Div: 3165.1394\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 10865.6885, KL Div: 3191.0598\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 10862.5029, KL Div: 3233.1770\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 10058.5234, KL Div: 3218.7695\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 10452.7988, KL Div: 3154.7935\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 10185.9375, KL Div: 3265.8032\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10146.3965, KL Div: 3132.9775\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 10413.1123, KL Div: 3244.4553\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10325.7666, KL Div: 3228.7036\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 10723.9219, KL Div: 3257.8374\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 10734.0000, KL Div: 3307.1616\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10537.5254, KL Div: 3220.0620\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 10577.7236, KL Div: 3169.7397\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 10506.0684, KL Div: 3220.6707\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10668.4102, KL Div: 3265.8022\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 10535.4893, KL Div: 3098.0088\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 10279.9629, KL Div: 3336.9624\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10606.7891, KL Div: 3168.9404\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10882.8438, KL Div: 3273.2661\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10984.1152, KL Div: 3201.7915\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 10464.0273, KL Div: 3313.7266\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10446.9521, KL Div: 3100.4019\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 10148.3818, KL Div: 3225.2383\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 10620.1279, KL Div: 3339.5005\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10372.7012, KL Div: 3062.8872\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 11121.3027, KL Div: 3380.9106\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 10769.9922, KL Div: 3260.7622\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 10526.7314, KL Div: 3116.5205\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10530.9141, KL Div: 3229.6094\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 11226.1309, KL Div: 3245.5569\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 10440.7900, KL Div: 3276.3745\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10839.4316, KL Div: 3257.9353\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10492.9678, KL Div: 3202.5972\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 10466.6768, KL Div: 3247.3164\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10588.2588, KL Div: 3212.3977\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 10593.3242, KL Div: 3229.9819\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 10619.9688, KL Div: 3216.9158\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10922.9297, KL Div: 3248.6108\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10619.2305, KL Div: 3277.1577\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 10721.2480, KL Div: 3219.9312\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 10698.1094, KL Div: 3249.6226\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10413.9844, KL Div: 3194.8093\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 9867.4043, KL Div: 3154.4785\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10573.0820, KL Div: 3285.9365\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10537.6377, KL Div: 3210.8755\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10708.5264, KL Div: 3162.7222\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 10475.8223, KL Div: 3199.2117\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 11225.8242, KL Div: 3227.8052\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 10660.4600, KL Div: 3214.3027\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10540.6484, KL Div: 3203.5820\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10734.0811, KL Div: 3241.4097\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10402.6729, KL Div: 3219.7097\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10126.7637, KL Div: 3242.2302\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10789.7539, KL Div: 3292.3643\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10839.4775, KL Div: 3233.9590\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10338.7627, KL Div: 3138.9282\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10622.2070, KL Div: 3172.7993\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10412.4473, KL Div: 3270.5535\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10449.4375, KL Div: 3091.0132\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 10607.5811, KL Div: 3290.0654\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10464.8730, KL Div: 3230.2517\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10681.5703, KL Div: 3253.1746\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 10204.8516, KL Div: 3071.5696\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10375.2295, KL Div: 3227.2424\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 10738.1758, KL Div: 3333.4709\n",
      "Epoch[8/15], Step [150/469], Reconst Loss: 10171.1953, KL Div: 3119.8638\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10670.2363, KL Div: 3267.4697\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10372.2148, KL Div: 3186.1343\n",
      "Epoch[8/15], Step [180/469], Reconst Loss: 10286.6055, KL Div: 3266.1611\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 10369.5332, KL Div: 3134.1323\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10512.5195, KL Div: 3110.2649\n",
      "Epoch[8/15], Step [210/469], Reconst Loss: 10259.1943, KL Div: 3298.8022\n",
      "Epoch[8/15], Step [220/469], Reconst Loss: 9874.5918, KL Div: 3127.4153\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10502.5879, KL Div: 3287.2910\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10371.9395, KL Div: 3264.1108\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 10695.2324, KL Div: 3225.4783\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10138.5996, KL Div: 3168.8926\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10185.7734, KL Div: 3233.8628\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10476.0820, KL Div: 3184.9500\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 10422.5557, KL Div: 3248.3232\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10361.5137, KL Div: 3365.4761\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 10507.0498, KL Div: 3248.2427\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10531.5869, KL Div: 3231.1753\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10512.0195, KL Div: 3309.4663\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 11161.1250, KL Div: 3129.8184\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 10422.3613, KL Div: 3243.6704\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10227.4766, KL Div: 3208.4316\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 10557.2461, KL Div: 3283.0430\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 10793.9375, KL Div: 3222.0786\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10711.7432, KL Div: 3145.6294\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10317.4521, KL Div: 3118.0542\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 10289.8408, KL Div: 3219.1804\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10274.1680, KL Div: 3157.9653\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10315.2236, KL Div: 3192.7239\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10399.7568, KL Div: 3293.6455\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 10365.7471, KL Div: 3313.7803\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10579.0498, KL Div: 3171.9312\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 10389.2197, KL Div: 3347.5898\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10683.3408, KL Div: 3175.0247\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10159.0439, KL Div: 3205.9209\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 10480.9688, KL Div: 3172.5137\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 10246.6514, KL Div: 3203.3364\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10512.4316, KL Div: 3360.2390\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10635.4346, KL Div: 3261.4556\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10234.1768, KL Div: 3171.5386\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 10741.5039, KL Div: 3372.1865\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10936.4707, KL Div: 3275.1104\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10179.9316, KL Div: 3328.6504\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10250.3613, KL Div: 3241.7585\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 10350.2451, KL Div: 3223.2075\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10410.6182, KL Div: 3252.7466\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 10550.2891, KL Div: 3324.2656\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10608.8584, KL Div: 3249.9746\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10570.4404, KL Div: 3155.2249\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 11090.3223, KL Div: 3344.9175\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10337.5039, KL Div: 3195.3574\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10561.3057, KL Div: 3224.0044\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10377.8818, KL Div: 3295.7095\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 10253.8057, KL Div: 3080.4121\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 10819.8721, KL Div: 3306.4482\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10505.1543, KL Div: 3218.7163\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10869.7803, KL Div: 3265.1924\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10111.3184, KL Div: 3131.0708\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 10616.6455, KL Div: 3217.3032\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10412.5176, KL Div: 3262.5107\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10418.3535, KL Div: 3141.9919\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10601.7607, KL Div: 3234.5786\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10576.4023, KL Div: 3278.8625\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10512.7354, KL Div: 3328.5266\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 10064.6426, KL Div: 3240.3062\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 10539.4258, KL Div: 3187.3892\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10569.7109, KL Div: 3300.1487\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10075.5381, KL Div: 3232.2754\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10524.7109, KL Div: 3232.5715\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 10266.4004, KL Div: 3257.6003\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 10078.3203, KL Div: 3245.3652\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10552.1338, KL Div: 3308.0889\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 10346.7158, KL Div: 3127.7810\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 10080.4531, KL Div: 3192.8628\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 10188.4912, KL Div: 3293.1223\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 10328.4727, KL Div: 3075.3123\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10007.2998, KL Div: 3234.1143\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10386.5547, KL Div: 3186.8745\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10408.1221, KL Div: 3169.1172\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 10843.5391, KL Div: 3247.3843\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 10129.8555, KL Div: 3385.4907\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 10602.8730, KL Div: 3096.3020\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10064.4541, KL Div: 3178.5007\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10904.5977, KL Div: 3285.6956\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 10408.6641, KL Div: 3228.0679\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 10801.6709, KL Div: 3230.2769\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 10227.7676, KL Div: 3141.5479\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10378.3242, KL Div: 3249.5464\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 10526.2148, KL Div: 3228.4973\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 9992.8555, KL Div: 3169.2791\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 10202.7900, KL Div: 3222.0857\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 10368.8008, KL Div: 3202.5928\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 9996.2275, KL Div: 3121.1548\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 10389.8955, KL Div: 3261.6980\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 9773.3740, KL Div: 3216.9473\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10537.9141, KL Div: 3353.8354\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 10401.7383, KL Div: 3256.1558\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10097.8770, KL Div: 3230.6875\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 10459.6895, KL Div: 3297.8687\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10679.2471, KL Div: 3224.7629\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10321.9648, KL Div: 3339.9463\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 10157.5117, KL Div: 3173.7859\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 10381.3359, KL Div: 3273.9023\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 10067.3398, KL Div: 3180.0527\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 10055.1621, KL Div: 3264.8918\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 10191.9502, KL Div: 3228.6108\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10864.2754, KL Div: 3353.9680\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10203.4199, KL Div: 3276.7290\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 9941.6309, KL Div: 3133.0654\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10430.2920, KL Div: 3259.7373\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 10174.1738, KL Div: 3190.5278\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10367.3633, KL Div: 3243.8862\n",
      "Epoch[10/15], Step [350/469], Reconst Loss: 10700.2432, KL Div: 3276.0137\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 10493.1758, KL Div: 3298.0505\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 10050.6133, KL Div: 3229.1572\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 9762.1982, KL Div: 3198.8845\n",
      "Epoch[10/15], Step [390/469], Reconst Loss: 10172.3301, KL Div: 3123.8628\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10311.8828, KL Div: 3313.2517\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 10691.7881, KL Div: 3298.3296\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10325.8438, KL Div: 3198.7388\n",
      "Epoch[10/15], Step [430/469], Reconst Loss: 10111.2129, KL Div: 3306.9829\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 10335.7822, KL Div: 3243.9771\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10246.4541, KL Div: 3195.5361\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 10061.7188, KL Div: 3251.9724\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 9931.9580, KL Div: 3117.0647\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 10037.1455, KL Div: 3303.7930\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 10213.5723, KL Div: 3176.2402\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 10029.5225, KL Div: 3246.4341\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10357.5879, KL Div: 3260.1106\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 10002.4521, KL Div: 3257.7295\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10162.3262, KL Div: 3234.5454\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 10392.9512, KL Div: 3275.6602\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 10093.6758, KL Div: 3229.6211\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10546.2793, KL Div: 3291.5483\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 10086.6445, KL Div: 3224.2139\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 10245.4199, KL Div: 3292.3145\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10617.6172, KL Div: 3220.8530\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 10131.4551, KL Div: 3258.9146\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 10230.3604, KL Div: 3240.9561\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 10412.8857, KL Div: 3277.9697\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10398.5371, KL Div: 3258.3145\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10566.3135, KL Div: 3264.7087\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 9909.9297, KL Div: 3195.7397\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 10336.8760, KL Div: 3273.3955\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10261.0352, KL Div: 3228.8760\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10547.3418, KL Div: 3326.3442\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 10199.3848, KL Div: 3188.8518\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10245.0586, KL Div: 3305.8594\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10076.5752, KL Div: 3223.8574\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 10634.1309, KL Div: 3352.6543\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 10117.7559, KL Div: 3226.7344\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 10486.4922, KL Div: 3253.5100\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 10321.4961, KL Div: 3199.4998\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 10421.3037, KL Div: 3315.7085\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 10255.8438, KL Div: 3302.8301\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 10009.4912, KL Div: 3204.6492\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 10435.3408, KL Div: 3287.9077\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 9815.7969, KL Div: 3248.4902\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 10221.2090, KL Div: 3159.3457\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 10571.2500, KL Div: 3290.2979\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 10322.3291, KL Div: 3164.6494\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 9883.5117, KL Div: 3288.9160\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 10424.2451, KL Div: 3238.1777\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 9985.8047, KL Div: 3291.8906\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 10594.0713, KL Div: 3359.5537\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10576.5586, KL Div: 3303.6680\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10457.3594, KL Div: 3214.0977\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 9941.0615, KL Div: 3314.5266\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 10057.4395, KL Div: 3188.9231\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 10389.7979, KL Div: 3204.1787\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 11043.9258, KL Div: 3399.6826\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 10241.4629, KL Div: 3323.4121\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 9725.9346, KL Div: 3129.1179\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 10458.0215, KL Div: 3172.5186\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 10493.6650, KL Div: 3193.9175\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 10387.5293, KL Div: 3267.4026\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 10282.9277, KL Div: 3206.1323\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 10289.5234, KL Div: 3421.7207\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 10353.1152, KL Div: 3218.4990\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10232.4160, KL Div: 3229.9993\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 10206.8564, KL Div: 3149.5405\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 10139.3652, KL Div: 3205.2976\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 10254.9043, KL Div: 3231.8179\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 9996.2754, KL Div: 3208.7734\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 10305.3086, KL Div: 3292.0664\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 9890.6377, KL Div: 3187.4028\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10148.3379, KL Div: 3208.0972\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10251.3418, KL Div: 3429.8101\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10450.5332, KL Div: 3172.0469\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 9807.8711, KL Div: 3180.3130\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 9985.1885, KL Div: 3237.4065\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 10192.4912, KL Div: 3229.6016\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 10291.9492, KL Div: 3195.4558\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 10868.9531, KL Div: 3340.6729\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 10503.7930, KL Div: 3335.3931\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10492.7939, KL Div: 3291.0366\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 9933.7549, KL Div: 3156.8101\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 10281.3350, KL Div: 3243.0298\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 10001.9189, KL Div: 3291.0645\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 9909.6074, KL Div: 3277.4270\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 10137.1777, KL Div: 3220.1069\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 9657.6816, KL Div: 3096.6936\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 9992.5117, KL Div: 3344.3140\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 10238.4014, KL Div: 3205.0310\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 10321.5996, KL Div: 3274.3181\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 10262.6973, KL Div: 3170.7012\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 9971.4932, KL Div: 3268.3816\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 10171.9805, KL Div: 3276.5276\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 10490.1523, KL Div: 3185.4131\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10051.7061, KL Div: 3296.6885\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 10456.8115, KL Div: 3226.8638\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 10010.1777, KL Div: 3309.3252\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 9943.4404, KL Div: 3270.1392\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10235.3066, KL Div: 3278.6865\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 10303.4023, KL Div: 3203.4236\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 10268.9932, KL Div: 3154.0183\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 10222.7012, KL Div: 3213.0127\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 10437.3613, KL Div: 3224.5303\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10111.9209, KL Div: 3377.7617\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 10289.5879, KL Div: 3150.5244\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 10565.7295, KL Div: 3319.5576\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 10589.7568, KL Div: 3346.7749\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 9640.7627, KL Div: 3150.8550\n",
      "Epoch[13/15], Step [80/469], Reconst Loss: 10666.4238, KL Div: 3237.2969\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 10277.0742, KL Div: 3315.4597\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10299.8926, KL Div: 3287.6838\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10008.6982, KL Div: 3234.8835\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10249.3330, KL Div: 3257.8311\n",
      "Epoch[13/15], Step [130/469], Reconst Loss: 10516.4414, KL Div: 3329.9453\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 9596.1182, KL Div: 3173.8757\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 10291.6914, KL Div: 3265.9712\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 10736.5332, KL Div: 3322.4973\n",
      "Epoch[13/15], Step [170/469], Reconst Loss: 10195.1152, KL Div: 3219.9543\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 10297.6309, KL Div: 3227.9419\n",
      "Epoch[13/15], Step [190/469], Reconst Loss: 10271.8613, KL Div: 3194.4653\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10502.1934, KL Div: 3269.0195\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 10028.8359, KL Div: 3204.0010\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 9725.9238, KL Div: 3330.4443\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10840.7402, KL Div: 3293.3687\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 10023.8809, KL Div: 3184.0276\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10284.5762, KL Div: 3262.0261\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 10177.8457, KL Div: 3237.6147\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 10148.8203, KL Div: 3228.9556\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 10497.0742, KL Div: 3308.0840\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10110.0625, KL Div: 3163.0144\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 9919.0039, KL Div: 3225.1104\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 10548.0352, KL Div: 3367.7236\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10406.5811, KL Div: 3138.3142\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10317.9717, KL Div: 3291.9512\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 9680.7598, KL Div: 3190.1895\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 10753.8438, KL Div: 3246.3918\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 10068.8857, KL Div: 3304.9653\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 10160.6719, KL Div: 3240.7295\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 10195.5127, KL Div: 3220.5210\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10252.9121, KL Div: 3207.8936\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 10127.1025, KL Div: 3276.3267\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 10050.2754, KL Div: 3258.5366\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 10502.7217, KL Div: 3282.1411\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10256.1504, KL Div: 3287.5808\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10306.2959, KL Div: 3193.0503\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 9896.6602, KL Div: 3329.2930\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 10345.3428, KL Div: 3235.0833\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 10070.9697, KL Div: 3316.6648\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 10099.0146, KL Div: 3088.6890\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10561.9717, KL Div: 3442.0894\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10391.5957, KL Div: 3216.0752\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 10531.1699, KL Div: 3220.9131\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 10298.4336, KL Div: 3313.5278\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 9889.3848, KL Div: 3200.9949\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 10591.0771, KL Div: 3288.4504\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 10276.9824, KL Div: 3378.3298\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 10496.4658, KL Div: 3200.6233\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 10367.7881, KL Div: 3285.3792\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10028.7998, KL Div: 3181.7070\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 10243.3760, KL Div: 3359.5933\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 9987.8438, KL Div: 3241.8223\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 10467.3203, KL Div: 3237.8904\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 10285.9961, KL Div: 3271.9619\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 10229.6455, KL Div: 3309.2261\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 10479.3008, KL Div: 3224.1255\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 10158.6289, KL Div: 3182.1492\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 10230.9316, KL Div: 3291.3328\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 10450.0850, KL Div: 3359.7385\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 10102.8633, KL Div: 3273.9009\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 9909.1455, KL Div: 3268.9116\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 10205.1729, KL Div: 3212.2251\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 9998.9414, KL Div: 3208.1311\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 10291.3691, KL Div: 3196.5225\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 10291.7471, KL Div: 3259.5908\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 10247.5273, KL Div: 3284.5913\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 9779.7959, KL Div: 3282.7429\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 9869.9863, KL Div: 3264.2949\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 10344.8047, KL Div: 3246.7595\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 10351.0977, KL Div: 3312.5146\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 10016.0527, KL Div: 3302.5732\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 9769.7520, KL Div: 3217.5029\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 10318.4004, KL Div: 3333.6504\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 10363.0674, KL Div: 3255.9817\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 10245.5430, KL Div: 3192.7446\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 10044.5566, KL Div: 3262.3049\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 10074.1689, KL Div: 3256.5332\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10131.7305, KL Div: 3311.1187\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 10519.3184, KL Div: 3255.3599\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 10073.8887, KL Div: 3150.8535\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 9992.4561, KL Div: 3180.1560\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 10022.9297, KL Div: 3251.6060\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 10323.2070, KL Div: 3257.0967\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 10111.0332, KL Div: 3233.8167\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 10244.4180, KL Div: 3201.6980\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 10588.4258, KL Div: 3384.8362\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 10447.6562, KL Div: 3267.2417\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 10170.2832, KL Div: 3330.0054\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 10121.4355, KL Div: 3216.0793\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 10680.1699, KL Div: 3252.1538\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 10261.1299, KL Div: 3253.0894\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10492.7227, KL Div: 3345.0283\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 10163.0000, KL Div: 3371.1448\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 10521.4639, KL Div: 3294.8101\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 10038.7285, KL Div: 3330.9043\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 9978.2637, KL Div: 3184.4670\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 9911.0430, KL Div: 3264.1025\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 10196.5303, KL Div: 3215.4045\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 10286.2949, KL Div: 3377.2185\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 9806.8086, KL Div: 3303.4658\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 10522.8613, KL Div: 3142.9595\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 10628.7080, KL Div: 3505.2722\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 9700.7148, KL Div: 3155.7510\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 10292.9922, KL Div: 3167.0723\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 10175.2314, KL Div: 3324.2407\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 10359.0117, KL Div: 3345.0737\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 10583.8760, KL Div: 3220.4092\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 9833.4961, KL Div: 3285.6042\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 10172.3682, KL Div: 3297.8394\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 9724.6182, KL Div: 3236.4556\n",
      "Epoch[15/15], Step [270/469], Reconst Loss: 10368.5352, KL Div: 3231.0654\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 10218.1895, KL Div: 3162.8149\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 10034.9609, KL Div: 3308.6094\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 9691.9180, KL Div: 3218.2407\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 9942.3643, KL Div: 3159.1440\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 9699.3438, KL Div: 3144.1562\n",
      "Epoch[15/15], Step [330/469], Reconst Loss: 10381.6240, KL Div: 3308.0562\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 10038.8809, KL Div: 3313.2305\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 10144.3721, KL Div: 3295.7710\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 9765.7031, KL Div: 3125.6426\n",
      "Epoch[15/15], Step [370/469], Reconst Loss: 9638.4492, KL Div: 3240.5066\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 10356.1270, KL Div: 3326.7954\n",
      "Epoch[15/15], Step [390/469], Reconst Loss: 10540.7998, KL Div: 3361.7993\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 9704.8291, KL Div: 3219.3003\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 10114.4531, KL Div: 3321.5430\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 9850.0371, KL Div: 3197.9333\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 9820.7500, KL Div: 3211.2373\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 10013.8750, KL Div: 3230.6997\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 10083.7471, KL Div: 3311.9954\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 10811.8125, KL Div: 3378.8447\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a directory if not exists\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                    train=True,\n",
    "                    transform=transforms.ToTensor(),\n",
    "                    download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                      batch_size=batch_size, \n",
    "                      shuffle=True)\n",
    "\n",
    "\n",
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKm8m3lBiMgb"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "11-variational_autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
