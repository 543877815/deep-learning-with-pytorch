{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VggNet\n",
    "\n",
    "https://pytorch.org/docs/stable/_modules/torchvision/models/vgg.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 80\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform_train,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                            train=False, \n",
    "                                            transform=transform_test)\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model):\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # For updating learning rate\n",
    "    def update_lr(optimizer, lr):    \n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    curr_lr = learning_rate\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "        # Decay learning rate\n",
    "        if (epoch+1) % 20 == 0:\n",
    "            curr_lr /= 3\n",
    "            update_lr(optimizer, curr_lr)\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.models.vgg11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg11 = torchvision.models.vgg11(pretrained=False, num_classes=10).to(device)\n",
    "print(vgg11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Step [100/500] Loss: 2.1483\n",
      "Epoch [1/80], Step [200/500] Loss: 1.6562\n",
      "Epoch [1/80], Step [300/500] Loss: 1.6417\n",
      "Epoch [1/80], Step [400/500] Loss: 1.5319\n",
      "Epoch [1/80], Step [500/500] Loss: 1.3974\n",
      "Epoch [2/80], Step [100/500] Loss: 1.2908\n",
      "Epoch [2/80], Step [200/500] Loss: 1.1963\n",
      "Epoch [2/80], Step [300/500] Loss: 1.3057\n",
      "Epoch [2/80], Step [400/500] Loss: 1.0490\n",
      "Epoch [2/80], Step [500/500] Loss: 1.0293\n",
      "Epoch [3/80], Step [100/500] Loss: 0.6678\n",
      "Epoch [3/80], Step [200/500] Loss: 1.2354\n",
      "Epoch [3/80], Step [300/500] Loss: 1.2113\n",
      "Epoch [3/80], Step [400/500] Loss: 0.8338\n",
      "Epoch [3/80], Step [500/500] Loss: 0.8505\n",
      "Epoch [4/80], Step [100/500] Loss: 0.7938\n",
      "Epoch [4/80], Step [200/500] Loss: 0.7747\n",
      "Epoch [4/80], Step [300/500] Loss: 0.6589\n",
      "Epoch [4/80], Step [400/500] Loss: 0.5734\n",
      "Epoch [4/80], Step [500/500] Loss: 0.9426\n",
      "Epoch [5/80], Step [100/500] Loss: 0.8212\n",
      "Epoch [5/80], Step [200/500] Loss: 0.7645\n",
      "Epoch [5/80], Step [300/500] Loss: 0.6647\n",
      "Epoch [5/80], Step [400/500] Loss: 0.8337\n",
      "Epoch [5/80], Step [500/500] Loss: 0.6879\n",
      "Epoch [6/80], Step [100/500] Loss: 0.5713\n",
      "Epoch [6/80], Step [200/500] Loss: 0.6702\n",
      "Epoch [6/80], Step [300/500] Loss: 0.5633\n",
      "Epoch [6/80], Step [400/500] Loss: 0.7337\n",
      "Epoch [6/80], Step [500/500] Loss: 0.7463\n",
      "Epoch [7/80], Step [100/500] Loss: 0.6179\n",
      "Epoch [7/80], Step [200/500] Loss: 0.6311\n",
      "Epoch [7/80], Step [300/500] Loss: 0.4685\n",
      "Epoch [7/80], Step [400/500] Loss: 0.5919\n",
      "Epoch [7/80], Step [500/500] Loss: 0.5044\n",
      "Epoch [8/80], Step [100/500] Loss: 0.3510\n",
      "Epoch [8/80], Step [200/500] Loss: 0.4603\n",
      "Epoch [8/80], Step [300/500] Loss: 0.3733\n",
      "Epoch [8/80], Step [400/500] Loss: 0.4703\n",
      "Epoch [8/80], Step [500/500] Loss: 0.8315\n",
      "Epoch [9/80], Step [100/500] Loss: 0.4301\n",
      "Epoch [9/80], Step [200/500] Loss: 0.4014\n",
      "Epoch [9/80], Step [300/500] Loss: 0.4157\n",
      "Epoch [9/80], Step [400/500] Loss: 0.6195\n",
      "Epoch [9/80], Step [500/500] Loss: 0.4357\n",
      "Epoch [10/80], Step [100/500] Loss: 0.4437\n",
      "Epoch [10/80], Step [200/500] Loss: 0.3932\n",
      "Epoch [10/80], Step [300/500] Loss: 0.3878\n",
      "Epoch [10/80], Step [400/500] Loss: 0.4451\n",
      "Epoch [10/80], Step [500/500] Loss: 0.2928\n",
      "Epoch [11/80], Step [100/500] Loss: 0.3417\n",
      "Epoch [11/80], Step [200/500] Loss: 0.4150\n",
      "Epoch [11/80], Step [300/500] Loss: 0.2942\n",
      "Epoch [11/80], Step [400/500] Loss: 0.4533\n",
      "Epoch [11/80], Step [500/500] Loss: 0.4632\n",
      "Epoch [12/80], Step [100/500] Loss: 0.2853\n",
      "Epoch [12/80], Step [200/500] Loss: 0.3304\n",
      "Epoch [12/80], Step [300/500] Loss: 0.3528\n",
      "Epoch [12/80], Step [400/500] Loss: 0.2145\n",
      "Epoch [12/80], Step [500/500] Loss: 0.2978\n",
      "Epoch [13/80], Step [100/500] Loss: 0.2507\n",
      "Epoch [13/80], Step [200/500] Loss: 0.3330\n",
      "Epoch [13/80], Step [300/500] Loss: 0.2635\n",
      "Epoch [13/80], Step [400/500] Loss: 0.3795\n",
      "Epoch [13/80], Step [500/500] Loss: 0.5850\n",
      "Epoch [14/80], Step [100/500] Loss: 0.1995\n",
      "Epoch [14/80], Step [200/500] Loss: 0.1871\n",
      "Epoch [14/80], Step [300/500] Loss: 0.2767\n",
      "Epoch [14/80], Step [400/500] Loss: 0.3315\n",
      "Epoch [14/80], Step [500/500] Loss: 0.3908\n",
      "Epoch [15/80], Step [100/500] Loss: 0.2116\n",
      "Epoch [15/80], Step [200/500] Loss: 0.2093\n",
      "Epoch [15/80], Step [300/500] Loss: 0.2086\n",
      "Epoch [15/80], Step [400/500] Loss: 0.2488\n",
      "Epoch [16/80], Step [300/500] Loss: 0.2828\n",
      "Epoch [16/80], Step [400/500] Loss: 0.2055\n",
      "Epoch [16/80], Step [500/500] Loss: 0.2478\n",
      "Epoch [17/80], Step [100/500] Loss: 0.1291\n",
      "Epoch [17/80], Step [200/500] Loss: 0.3157\n",
      "Epoch [17/80], Step [300/500] Loss: 0.1720\n",
      "Epoch [17/80], Step [400/500] Loss: 0.2744\n",
      "Epoch [17/80], Step [500/500] Loss: 0.3103\n",
      "Epoch [18/80], Step [100/500] Loss: 0.1920\n",
      "Epoch [18/80], Step [200/500] Loss: 0.1241\n",
      "Epoch [18/80], Step [300/500] Loss: 0.2097\n",
      "Epoch [18/80], Step [400/500] Loss: 0.1902\n",
      "Epoch [18/80], Step [500/500] Loss: 0.1992\n",
      "Epoch [19/80], Step [100/500] Loss: 0.2084\n",
      "Epoch [19/80], Step [200/500] Loss: 0.1395\n",
      "Epoch [19/80], Step [300/500] Loss: 0.1582\n",
      "Epoch [19/80], Step [400/500] Loss: 0.2023\n",
      "Epoch [19/80], Step [500/500] Loss: 0.1266\n",
      "Epoch [20/80], Step [300/500] Loss: 0.1896\n",
      "Epoch [20/80], Step [400/500] Loss: 0.2352\n",
      "Epoch [20/80], Step [500/500] Loss: 0.2216\n",
      "Epoch [21/80], Step [200/500] Loss: 0.0670\n",
      "Epoch [21/80], Step [300/500] Loss: 0.0604\n",
      "Epoch [21/80], Step [400/500] Loss: 0.0823\n",
      "Epoch [21/80], Step [500/500] Loss: 0.0273\n",
      "Epoch [22/80], Step [100/500] Loss: 0.0213\n",
      "Epoch [22/80], Step [200/500] Loss: 0.0856\n",
      "Epoch [22/80], Step [300/500] Loss: 0.1181\n",
      "Epoch [22/80], Step [400/500] Loss: 0.1061\n",
      "Epoch [22/80], Step [500/500] Loss: 0.0966\n",
      "Epoch [23/80], Step [100/500] Loss: 0.0317\n",
      "Epoch [23/80], Step [200/500] Loss: 0.0290\n",
      "Epoch [23/80], Step [300/500] Loss: 0.1283\n",
      "Epoch [23/80], Step [400/500] Loss: 0.1573\n",
      "Epoch [23/80], Step [500/500] Loss: 0.1451\n",
      "Epoch [24/80], Step [100/500] Loss: 0.0845\n",
      "Epoch [24/80], Step [200/500] Loss: 0.0626\n",
      "Epoch [24/80], Step [300/500] Loss: 0.0497\n",
      "Epoch [24/80], Step [400/500] Loss: 0.0241\n",
      "Epoch [24/80], Step [500/500] Loss: 0.0142\n",
      "Epoch [25/80], Step [100/500] Loss: 0.0157\n",
      "Epoch [25/80], Step [200/500] Loss: 0.0157\n",
      "Epoch [25/80], Step [300/500] Loss: 0.0347\n",
      "Epoch [25/80], Step [400/500] Loss: 0.0824\n",
      "Epoch [25/80], Step [500/500] Loss: 0.0967\n",
      "Epoch [26/80], Step [100/500] Loss: 0.0101\n",
      "Epoch [26/80], Step [200/500] Loss: 0.0463\n",
      "Epoch [26/80], Step [300/500] Loss: 0.0769\n",
      "Epoch [26/80], Step [400/500] Loss: 0.0320\n",
      "Epoch [26/80], Step [500/500] Loss: 0.1912\n",
      "Epoch [27/80], Step [100/500] Loss: 0.0371\n",
      "Epoch [27/80], Step [200/500] Loss: 0.0216\n",
      "Epoch [27/80], Step [300/500] Loss: 0.0789\n",
      "Epoch [27/80], Step [400/500] Loss: 0.0521\n",
      "Epoch [27/80], Step [500/500] Loss: 0.0376\n",
      "Epoch [28/80], Step [100/500] Loss: 0.0296\n",
      "Epoch [28/80], Step [200/500] Loss: 0.0052\n",
      "Epoch [28/80], Step [300/500] Loss: 0.0124\n",
      "Epoch [28/80], Step [400/500] Loss: 0.0301\n",
      "Epoch [28/80], Step [500/500] Loss: 0.0274\n",
      "Epoch [29/80], Step [100/500] Loss: 0.0239\n",
      "Epoch [29/80], Step [200/500] Loss: 0.0067\n",
      "Epoch [29/80], Step [300/500] Loss: 0.0125\n",
      "Epoch [29/80], Step [400/500] Loss: 0.0084\n",
      "Epoch [29/80], Step [500/500] Loss: 0.0551\n",
      "Epoch [30/80], Step [100/500] Loss: 0.0031\n",
      "Epoch [30/80], Step [200/500] Loss: 0.0043\n",
      "Epoch [30/80], Step [300/500] Loss: 0.0567\n",
      "Epoch [30/80], Step [400/500] Loss: 0.0129\n",
      "Epoch [30/80], Step [500/500] Loss: 0.0174\n",
      "Epoch [31/80], Step [100/500] Loss: 0.0155\n",
      "Epoch [31/80], Step [200/500] Loss: 0.0248\n",
      "Epoch [31/80], Step [300/500] Loss: 0.0992\n",
      "Epoch [31/80], Step [400/500] Loss: 0.0128\n",
      "Epoch [31/80], Step [500/500] Loss: 0.0036\n",
      "Epoch [32/80], Step [100/500] Loss: 0.0465\n",
      "Epoch [32/80], Step [200/500] Loss: 0.0054\n",
      "Epoch [32/80], Step [300/500] Loss: 0.0252\n",
      "Epoch [32/80], Step [400/500] Loss: 0.0299\n",
      "Epoch [32/80], Step [500/500] Loss: 0.0970\n",
      "Epoch [33/80], Step [100/500] Loss: 0.0156\n",
      "Epoch [33/80], Step [200/500] Loss: 0.0349\n",
      "Epoch [33/80], Step [300/500] Loss: 0.0480\n",
      "Epoch [33/80], Step [400/500] Loss: 0.0118\n",
      "Epoch [33/80], Step [500/500] Loss: 0.0374\n",
      "Epoch [34/80], Step [100/500] Loss: 0.0054\n",
      "Epoch [34/80], Step [200/500] Loss: 0.0253\n",
      "Epoch [34/80], Step [300/500] Loss: 0.0619\n",
      "Epoch [34/80], Step [400/500] Loss: 0.0196\n",
      "Epoch [34/80], Step [500/500] Loss: 0.0681\n",
      "Epoch [35/80], Step [100/500] Loss: 0.0289\n",
      "Epoch [35/80], Step [200/500] Loss: 0.0079\n",
      "Epoch [35/80], Step [300/500] Loss: 0.0095\n",
      "Epoch [35/80], Step [400/500] Loss: 0.0323\n",
      "Epoch [35/80], Step [500/500] Loss: 0.0034\n",
      "Epoch [36/80], Step [100/500] Loss: 0.0109\n",
      "Epoch [36/80], Step [200/500] Loss: 0.0003\n",
      "Epoch [36/80], Step [300/500] Loss: 0.0053\n",
      "Epoch [36/80], Step [400/500] Loss: 0.0439\n",
      "Epoch [36/80], Step [500/500] Loss: 0.0264\n",
      "Epoch [37/80], Step [100/500] Loss: 0.0114\n",
      "Epoch [37/80], Step [400/500] Loss: 0.0574\n",
      "Epoch [37/80], Step [500/500] Loss: 0.0257\n",
      "Epoch [38/80], Step [100/500] Loss: 0.0046\n",
      "Epoch [38/80], Step [200/500] Loss: 0.1303\n",
      "Epoch [38/80], Step [300/500] Loss: 0.0157\n",
      "Epoch [38/80], Step [400/500] Loss: 0.0020\n",
      "Epoch [38/80], Step [500/500] Loss: 0.0106\n",
      "Epoch [39/80], Step [100/500] Loss: 0.0072\n",
      "Epoch [39/80], Step [200/500] Loss: 0.0073\n",
      "Epoch [39/80], Step [300/500] Loss: 0.0510\n",
      "Epoch [39/80], Step [400/500] Loss: 0.0101\n",
      "Epoch [39/80], Step [500/500] Loss: 0.0148\n",
      "Epoch [40/80], Step [100/500] Loss: 0.0085\n",
      "Epoch [40/80], Step [200/500] Loss: 0.0004\n",
      "Epoch [40/80], Step [300/500] Loss: 0.0343\n",
      "Epoch [40/80], Step [400/500] Loss: 0.0004\n",
      "Epoch [40/80], Step [500/500] Loss: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/80], Step [100/500] Loss: 0.0029\n",
      "Epoch [41/80], Step [200/500] Loss: 0.0521\n",
      "Epoch [41/80], Step [300/500] Loss: 0.0018\n",
      "Epoch [41/80], Step [400/500] Loss: 0.0013\n",
      "Epoch [41/80], Step [500/500] Loss: 0.0011\n",
      "Epoch [42/80], Step [100/500] Loss: 0.0013\n",
      "Epoch [42/80], Step [200/500] Loss: 0.0007\n",
      "Epoch [42/80], Step [300/500] Loss: 0.0169\n",
      "Epoch [42/80], Step [400/500] Loss: 0.0008\n",
      "Epoch [42/80], Step [500/500] Loss: 0.0009\n",
      "Epoch [43/80], Step [100/500] Loss: 0.0003\n",
      "Epoch [43/80], Step [200/500] Loss: 0.0006\n",
      "Epoch [43/80], Step [300/500] Loss: 0.0014\n",
      "Epoch [43/80], Step [400/500] Loss: 0.0253\n",
      "Epoch [43/80], Step [500/500] Loss: 0.0008\n",
      "Epoch [44/80], Step [100/500] Loss: 0.0472\n",
      "Epoch [44/80], Step [200/500] Loss: 0.0638\n",
      "Epoch [44/80], Step [300/500] Loss: 0.0013\n",
      "Epoch [44/80], Step [400/500] Loss: 0.0057\n",
      "Epoch [44/80], Step [500/500] Loss: 0.0155\n",
      "Epoch [45/80], Step [100/500] Loss: 0.0003\n",
      "Epoch [45/80], Step [200/500] Loss: 0.0019\n",
      "Epoch [45/80], Step [300/500] Loss: 0.0623\n",
      "Epoch [45/80], Step [400/500] Loss: 0.0016\n",
      "Epoch [45/80], Step [500/500] Loss: 0.0012\n",
      "Epoch [46/80], Step [100/500] Loss: 0.0797\n",
      "Epoch [46/80], Step [200/500] Loss: 0.0031\n"
     ]
    }
   ],
   "source": [
    "train_and_test(vgg11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.models.vgg11_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg11_bn = torchvision.models.vgg11_bn(pretrained=False, num_classes=10)\n",
    "print(vgg11_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.models.vgg13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): ReLU(inplace)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): ReLU(inplace)\n",
      "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg13 = torchvision.models.vgg13(pretrained=False, num_classes=10)\n",
    "print(vgg13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.models.vgg13_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ReLU(inplace)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): ReLU(inplace)\n",
      "    (31): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (33): ReLU(inplace)\n",
      "    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg13_bn = torchvision.models.vgg13_bn(pretrained=False, num_classes=10)\n",
    "print(vgg13_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.models.vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = torchvision.models.vgg16(pretrained=False, num_classes=10)\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.models.vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg19 = torchvision.models.vgg19(pretrained=False, num_classes=10)\n",
    "print(vgg19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision.models.vgg19_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg19_bn = torchvision.models.vgg19_bn(pretrained=False, num_classes=10)\n",
    "print(vgg19_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
